# -*- coding: utf-8 -*-
"""carssales2024.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZjlqokWIefylCOGNWFJQypFwiPu9TdGj

**India Car Sales 2024 - Comprehensive Data Analysis**
Dataset Overview
This dataset contains monthly car sales data for the **Indian automotive market in 2024**, covering 18 car manufacturers and 89 different models across various segments and body types
"""

from PIL import Image
img = Image.open('/content/1175431.jpg')
img

import pandas as pd
df=pd.read_csv('/content/Car Sales in India - 2024.csv')
df

df.shape

df.dtypes

df.info()

df.head(20)

df.tail(20)

df.describe()

df.value_counts()

df.isnull()

df['January'].mean()

df['Total'].median()

df.dropna(inplace=True)
df.head()

"""**Top Performing Brands by Total Sales**:

**Maruti Suzuki** - 1,543,517 units (Market Leader)
**Hyundai** - 539,151 units
**Tata Motors** - 520,102 units
**Mahindra** - 448,460 units
**Toyota** - 295,720 units
"""

import plotly.express as px


fig = px.bar(df, x = "Make", y = "Total")
fig.show()

df1=df.sort_values(by='Total',ascending=False).head()
print(df1)

"""# Brand Analysis
**Maruti Suzuki** maintains clear market leadership with 42.8% share, followed by **Hyundai** (16.3%) and **Tata **(16.2%). The competition is intensifying with Tata showing strong growth in the SUV segment.
"""

import plotly.express as px


fig = px.bar(df1, x = "Make", y = "Total")
fig.show()

"""**Segment Insights**

**SUV Dominance**: 1.8M units (57% of total sales)
**Hatchbacks**: 650K units (20% share)
**Sedans**: 380K units (12% share) - declining segment
**MUVs**: 350K units (11% share
"""

import seaborn as sns
sns.countplot(data=df, x='Body Type',width=0.6);

import plotly.express as px
fig = px.pie(df, values="Total", names="Body Type")
fig.show()

"""**High-Performing Models:**

**Tata Punch**: Leading with a total of 202,031 units, showing consistent growth (+9% MoM).

**Hyundai Creta**: Strong sales with 186,919 units, though experiencing a decline (-18% MoM).

**Maruti WagonR**: Substantial sales of 190,855 units, with a positive YoY increase (102%).


"""

import plotly.express as px


fig = px.bar(df1, x = "Model", y = "Total")
fig.show()

"""**Segment Performance**:

**C1 Segment** (Compact): Highest volume segment
**C2 Segment** (Mid-size): Strong performance, especially SUVs
**B2 Segment** (Premium hatchback): Stable market
**Utility Segment**: Consistent demand for practical vehicles
"""

import plotly.express as px


fig = px.bar(df1, x = "Segment", y = "Total")
fig.show()

import pandas as pd
df=pd.read_csv('/content/Car Sales in India - 2024.csv')

df2=df.sort_values(by='YoY %',ascending=False).head()
print(df2)

"""**High Growth Models (YoY %)**

**Kia Seltos**: -72% (facing increased competition)
**Maruti Alto**: +197% (remarkable comeback)
**Maruti Celerio**: +203% (strong recovery)
**Maruti WagonR**: +102% (consistent performer)
**Mahindra XUV300/3X0**: +97% (successful refresh
"""

import plotly.express as px


fig = px.bar(df2, x = "Model", y = "Total")
fig.show()

"""**Declining Models (YoY %)**

**Citroen Aircross**: -72% (struggling in competitive SUV space)
**Hyundai Ioniq 5**: -70% (EV market challenges)
**Maruti S-Presso**: -87% (market rejection)
"""

df3=df.sort_values(by='YoY %',ascending=True).head()
print(df3)

import plotly.express as px


fig = px.bar(df3, x = "Model", y = "Total")
fig.show()

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

df = pd.read_csv('/content/Car Sales in India - 2024.csv')
sns.heatmap(df.corr(numeric_only=True),center=0,cmap='Reds')
plt.title("multicollinearity of car attributes")

a,b=plt.subplots(figsize=(10,5))
sns.heatmap(df.corr(numeric_only=True),center=0,cmap='BrBG',annot=True)

# Car Sales Data - Linear Regression Analysis
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.ensemble import RandomForestRegressor
import warnings
warnings.filterwarnings('ignore')

# Set style for better plots
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("üöó Car Sales Linear Regression Analysis")
print("=" * 50)

# # Load the data
df = pd.read_csv('Car Sales in India - 2024.csv')

print("Dataset Overview:")
print(f"Shape: {df.shape}")
print(f"Columns: {list(df.columns)}")
print("\nFirst few rows:")
print(df.head())

# Data preprocessing
print("\n" + "="*50)
print("DATA PREPROCESSING")
print("="*50)

# Check for missing values
print("\nMissing values:")
print(df.isnull().sum())

# Handle missing values (if any)
# For numeric columns, fill with median
numeric_columns = ['January', 'February', 'March', 'April', 'May', 'June',
                  'July', 'August', 'September', 'October ', 'November ', 'December',
                  'Total', 'MoM %', 'YoY %']

for col in numeric_columns:
    if col in df.columns:
        # Convert to numeric, handling any non-numeric values
        df[col] = pd.to_numeric(df[col], errors='coerce')
        df[col] = df[col].fillna(df[col].median())

# Basic statistics
print("\nBasic Statistics:")
print(df.describe())

# Feature Engineering
print("\n" + "="*50)
print("FEATURE ENGINEERING")
print("="*50)

# Create additional features
df['Monthly_Average'] = df[['January', 'February', 'March', 'April', 'May', 'June',
                           'July', 'August', 'September', 'October ', 'November ', 'December']].mean(axis=1)

df['Q1_Sales'] = df[['January', 'February', 'March']].sum(axis=1)
df['Q2_Sales'] = df[['April', 'May', 'June']].sum(axis=1)
df['Q3_Sales'] = df[['July', 'August', 'September']].sum(axis=1)
df['Q4_Sales'] = df[['October ', 'November ', 'December']].sum(axis=1)

df['H1_Sales'] = df['Q1_Sales'] + df['Q2_Sales']
df['H2_Sales'] = df['Q3_Sales'] + df['Q4_Sales']

# Calculate seasonal variation
df['Seasonal_Variation'] = df[['Q1_Sales', 'Q2_Sales', 'Q3_Sales', 'Q4_Sales']].std(axis=1)

# Encode categorical variables
le_make = LabelEncoder()
le_segment = LabelEncoder()
le_body_type = LabelEncoder()

df['Make_Encoded'] = le_make.fit_transform(df['Make'])
df['Segment_Encoded'] = le_segment.fit_transform(df['Segment'])
df['Body_Type_Encoded'] = le_body_type.fit_transform(df['Body Type'])

print("Feature engineering completed!")
print(f"New features created: Monthly_Average, Q1-Q4_Sales, H1-H2_Sales, Seasonal_Variation")

# Exploratory Data Analysis
print("\n" + "="*50)
print("EXPLORATORY DATA ANALYSIS")
print("="*50)

# Create visualizations
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# Total sales distribution
axes[0,0].hist(df['Total'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
axes[0,0].set_title('Distribution of Total Sales')
axes[0,0].set_xlabel('Total Sales')
axes[0,0].set_ylabel('Frequency')

# Sales by Make (top 10)
top_makes = df.groupby('Make')['Total'].sum().sort_values(ascending=False).head(10)
axes[0,1].bar(range(len(top_makes)), top_makes.values, color='lightcoral')
axes[0,1].set_title('Top 10 Makes by Total Sales')
axes[0,1].set_xlabel('Make')
axes[0,1].set_ylabel('Total Sales')
axes[0,1].set_xticks(range(len(top_makes)))
axes[0,1].set_xticklabels(top_makes.index, rotation=45)

# Sales by Body Type
body_type_sales = df.groupby('Body Type')['Total'].sum().sort_values(ascending=False)
axes[1,0].bar(range(len(body_type_sales)), body_type_sales.values, color='lightgreen')
axes[1,0].set_title('Sales by Body Type')
axes[1,0].set_xlabel('Body Type')
axes[1,0].set_ylabel('Total Sales')
axes[1,0].set_xticks(range(len(body_type_sales)))
axes[1,0].set_xticklabels(body_type_sales.index, rotation=45)

# Monthly sales trend (average across all models)
monthly_avg = df[['January', 'February', 'March', 'April', 'May', 'June',
                 'July', 'August', 'September', 'October ', 'November ', 'December']].mean()
axes[1,1].plot(monthly_avg.index, monthly_avg.values, marker='o', linewidth=2, markersize=6)
axes[1,1].set_title('Average Monthly Sales Trend')
axes[1,1].set_xlabel('Month')
axes[1,1].set_ylabel('Average Sales')
axes[1,1].tick_params(axis='x', rotation=45)

plt.tight_layout()
plt.show()

# Correlation analysis
print("\nCorrelation Analysis:")
correlation_features = ['Monthly_Average', 'Q1_Sales', 'Q2_Sales', 'Q3_Sales', 'Q4_Sales',
                       'H1_Sales', 'H2_Sales', 'Seasonal_Variation', 'MoM %', 'YoY %', 'Total']
corr_matrix = df[correlation_features].corr()

plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0,
            square=True, linewidths=0.5, cbar_kws={"shrink": .8})
plt.title('Feature Correlation Matrix')
plt.tight_layout()
plt.show()

# LINEAR REGRESSION MODELS
print("\n" + "="*50)
print("LINEAR REGRESSION ANALYSIS")
print("="*50)

# Model 1: Predict Total Sales using monthly data
print("\n1. MODEL 1: Predicting Total Sales using Monthly Data")
print("-" * 50)

X1 = df[['January', 'February', 'March', 'April', 'May', 'June',
         'July', 'August', 'September', 'October ', 'November ', 'December']]
y1 = df['Total']

X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2, random_state=42)

model1 = LinearRegression()
model1.fit(X1_train, y1_train)
y1_pred = model1.predict(X1_test)

print(f"R¬≤ Score: {r2_score(y1_test, y1_pred):.4f}")
print(f"Mean Squared Error: {mean_squared_error(y1_test, y1_pred):.2f}")
print(f"Mean Absolute Error: {mean_absolute_error(y1_test, y1_pred):.2f}")

# Model 2: Predict Total Sales using quarterly data + categorical features
print("\n2. MODEL 2: Predicting Total Sales using Quarterly + Categorical Data")
print("-" * 50)

X2 = df[['Q1_Sales', 'Q2_Sales', 'Q3_Sales', 'Q4_Sales', 'Make_Encoded',
         'Segment_Encoded', 'Body_Type_Encoded', 'Seasonal_Variation']]
y2 = df['Total']

X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)

model2 = LinearRegression()
model2.fit(X2_train, y2_train)
y2_pred = model2.predict(X2_test)

print(f"R¬≤ Score: {r2_score(y2_test, y2_pred):.4f}")
print(f"Mean Squared Error: {mean_squared_error(y2_test, y2_pred):.2f}")
print(f"Mean Absolute Error: {mean_absolute_error(y2_test, y2_pred):.2f}")

# Model 3: Predict MoM% using various features
print("\n3. MODEL 3: Predicting Month-over-Month Growth (%)")
print("-" * 50)

# Remove rows with extreme MoM% values for better model performance
df_clean = df[abs(df['MoM %']) < 1000].copy()

X3 = df_clean[['Monthly_Average', 'Seasonal_Variation', 'Make_Encoded',
               'Segment_Encoded', 'Body_Type_Encoded', 'YoY %']]
y3 = df_clean['MoM %']

X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)

model3 = LinearRegression()
model3.fit(X3_train, y3_train)
y3_pred = model3.predict(X3_test)

print(f"R¬≤ Score: {r2_score(y3_test, y3_pred):.4f}")
print(f"Mean Squared Error: {mean_squared_error(y3_test, y3_pred):.2f}")
print(f"Mean Absolute Error: {mean_absolute_error(y3_test, y3_pred):.2f}")

# Visualize predictions vs actual values
fig, axes = plt.subplots(1, 3, figsize=(18, 5))

# Model 1 predictions
axes[0].scatter(y1_test, y1_pred, alpha=0.6, color='blue')
axes[0].plot([y1_test.min(), y1_test.max()], [y1_test.min(), y1_test.max()], 'r--', lw=2)
axes[0].set_xlabel('Actual Total Sales')
axes[0].set_ylabel('Predicted Total Sales')
axes[0].set_title(f'Model 1: Monthly Data\nR¬≤ = {r2_score(y1_test, y1_pred):.3f}')

# Model 2 predictions
axes[1].scatter(y2_test, y2_pred, alpha=0.6, color='green')
axes[1].plot([y2_test.min(), y2_test.max()], [y2_test.min(), y2_test.max()], 'r--', lw=2)
axes[1].set_xlabel('Actual Total Sales')
axes[1].set_ylabel('Predicted Total Sales')
axes[1].set_title(f'Model 2: Quarterly + Categorical\nR¬≤ = {r2_score(y2_test, y2_pred):.3f}')

# Model 3 predictions
axes[2].scatter(y3_test, y3_pred, alpha=0.6, color='orange')
axes[2].plot([y3_test.min(), y3_test.max()], [y3_test.min(), y3_test.max()], 'r--', lw=2)
axes[2].set_xlabel('Actual MoM %')
axes[2].set_ylabel('Predicted MoM %')
axes[2].set_title(f'Model 3: MoM Growth\nR¬≤ = {r2_score(y3_test, y3_pred):.3f}')

plt.tight_layout()
plt.show()

# Feature importance analysis
print("\n" + "="*50)
print("FEATURE IMPORTANCE ANALYSIS")
print("="*50)

# Feature importance for Model 2 (best performing model for total sales)
feature_names = ['Q1_Sales', 'Q2_Sales', 'Q3_Sales', 'Q4_Sales', 'Make_Encoded',
                'Segment_Encoded', 'Body_Type_Encoded', 'Seasonal_Variation']
feature_importance = abs(model2.coef_)
feature_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})
feature_df = feature_df.sort_values('Importance', ascending=False)

plt.figure(figsize=(10, 6))
plt.bar(feature_df['Feature'], feature_df['Importance'], color='skyblue', edgecolor='navy')
plt.title('Feature Importance (Model 2: Total Sales Prediction)')
plt.xlabel('Features')
plt.ylabel('Coefficient Magnitude')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print("\nTop 5 Most Important Features:")
print(feature_df.head())

# Business Insights
print("\n" + "="*50)
print("BUSINESS INSIGHTS")
print("="*50)

print("\nüìä KEY FINDINGS:")
print(f"‚Ä¢ Best performing model: Model 2 (R¬≤ = {r2_score(y2_test, y2_pred):.3f})")
print(f"‚Ä¢ Total cars sold in 2024: {df['Total'].sum():,}")
print(f"‚Ä¢ Average monthly sales per model: {df['Monthly_Average'].mean():.0f}")
print(f"‚Ä¢ Most successful brand: {df.groupby('Make')['Total'].sum().idxmax()}")
print(f"‚Ä¢ Most popular body type: {df.groupby('Body Type')['Total'].sum().idxmax()}")

# Top performing models
print(f"\nüèÜ TOP 5 BEST-SELLING MODELS:")
top_models = df.nlargest(5, 'Total')[['Make', 'Model', 'Total']]
for idx, row in top_models.iterrows():
    print(f"‚Ä¢ {row['Make']} {row['Model']}: {row['Total']:,} units")

print(f"\nüìà GROWTH ANALYSIS:")
positive_growth = df[df['YoY %'] > 0]
print(f"‚Ä¢ Models with positive YoY growth: {len(positive_growth)}/{len(df)} ({len(positive_growth)/len(df)*100:.1f}%)")
print(f"‚Ä¢ Average YoY growth: {df['YoY %'].mean():.1f}%")

print(f"\nüéØ RECOMMENDATIONS:")
print("‚Ä¢ Focus on SUV segment - highest total sales")
print("‚Ä¢ Monitor seasonal variations for inventory planning")
print("‚Ä¢ Investigate models with negative growth for improvement opportunities")
print("‚Ä¢ Leverage quarterly sales patterns for targeted marketing campaigns")

print("\n" + "="*50)
print("ANALYSIS COMPLETE! üéâ")
print("="*50)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.tree import plot_tree, export_text
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Set display options
pd.set_option('display.max_columns', None)
pd.set_option('display.width', None)

print("=== Car Sales Analysis in India - 2024 ===")
print("Decision Tree Analysis\n")


    df = pd.read_csv('Car Sales in India - 2024.csv')
    print("‚úÖ Dataset loaded successfully!")
except FileNotFoundError:
    print("‚ùå Please upload the 'Car Sales in India - 2024.csv' file to Colab")
    print("Use the file upload button in the left sidebar")

# Display basic information about the dataset
print(f"\nüìä Dataset Shape: {df.shape}")
print(f"Columns: {len(df.columns)}")
print(f"Rows: {len(df)}")

# Display first few rows
print("\nüîç First 5 rows of the dataset:")
print(df.head())

# Check for missing values
print("\nüîç Missing Values:")
print(df.isnull().sum())

# Basic statistics
print("\nüìà Basic Statistics:")
print(df.describe())

# Data types
print("\nüîç Data Types:")
print(df.dtypes)

# =======================
# DATA PREPROCESSING
# =======================

print("\n=== DATA PREPROCESSING ===")

# Clean column names (remove extra spaces)
df.columns = df.columns.str.strip()

# Handle the comma in Ignis February data (assuming it's a typo)
df.loc[df['Model'] == 'Ignis', 'February'] = df.loc[df['Model'] == 'Ignis', 'February'].str.replace(',', '')
df['February'] = pd.to_numeric(df['February'], errors='coerce')

# Fill any remaining NaN values with 0 for monthly sales
monthly_cols = ['January', 'February', 'March', 'April', 'May', 'June',
                'July', 'August', 'September', 'October', 'November', 'December']
df[monthly_cols] = df[monthly_cols].fillna(0)

# Calculate additional features
df['Average_Monthly_Sales'] = df[monthly_cols].mean(axis=1)
df['Sales_Variance'] = df[monthly_cols].var(axis=1)
df['Peak_Month_Sales'] = df[monthly_cols].max(axis=1)
df['Min_Month_Sales'] = df[monthly_cols].min(axis=1)
df['Sales_Range'] = df['Peak_Month_Sales'] - df['Min_Month_Sales']

# Create performance categories based on total sales
df['Performance_Category'] = pd.cut(df['Total'],
                                   bins=[0, 5000, 20000, 50000, 100000, float('inf')],
                                   labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])

print("‚úÖ Data preprocessing completed!")
print(f"New features added: Average_Monthly_Sales, Sales_Variance, Peak_Month_Sales, Min_Month_Sales, Sales_Range, Performance_Category")

# =======================
# EXPLORATORY DATA ANALYSIS
# =======================

print("\n=== EXPLORATORY DATA ANALYSIS ===")

# Set up the plotting style
plt.style.use('seaborn-v0_8')
fig, axes = plt.subplots(2, 2, figsize=(15, 12))

# 1. Distribution of Total Sales
axes[0, 0].hist(df['Total'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
axes[0, 0].set_title('Distribution of Total Sales', fontsize=14, fontweight='bold')
axes[0, 0].set_xlabel('Total Sales')
axes[0, 0].set_ylabel('Frequency')

# 2. Sales by Segment
segment_sales = df.groupby('Segment')['Total'].sum().sort_values(ascending=False)
axes[0, 1].bar(segment_sales.index, segment_sales.values, color='lightcoral')
axes[0, 1].set_title('Total Sales by Segment', fontsize=14, fontweight='bold')
axes[0, 1].set_xlabel('Segment')
axes[0, 1].set_ylabel('Total Sales')
axes[0, 1].tick_params(axis='x', rotation=45)

# 3. Sales by Body Type
body_sales = df.groupby('Body Type')['Total'].sum().sort_values(ascending=False)
axes[1, 0].bar(body_sales.index, body_sales.values, color='lightgreen')
axes[1, 0].set_title('Total Sales by Body Type', fontsize=14, fontweight='bold')
axes[1, 0].set_xlabel('Body Type')
axes[1, 0].set_ylabel('Total Sales')
axes[1, 0].tick_params(axis='x', rotation=45)

# 4. Performance Category Distribution
perf_counts = df['Performance_Category'].value_counts()
axes[1, 1].pie(perf_counts.values, labels=perf_counts.index, autopct='%1.1f%%', startangle=90)
axes[1, 1].set_title('Performance Category Distribution', fontsize=14, fontweight='bold')

plt.tight_layout()
plt.show()

# Top performing models
print("\nüèÜ Top 10 Best Selling Models:")
top_models = df.nlargest(10, 'Total')[['Make', 'Model', 'Total', 'Segment', 'Body Type']]
print(top_models)

# =======================
# DECISION TREE ANALYSIS
# =======================

print("\n=== DECISION TREE ANALYSIS ===")

# Prepare features for decision tree
# Encode categorical variables
le_make = LabelEncoder()
le_segment = LabelEncoder()
le_body_type = LabelEncoder()

df_encoded = df.copy()
df_encoded['Make_encoded'] = le_make.fit_transform(df['Make'])
df_encoded['Segment_encoded'] = le_segment.fit_transform(df['Segment'])
df_encoded['Body_Type_encoded'] = le_body_type.fit_transform(df['Body Type'])

# =======================
# DECISION TREE CLASSIFIER
# =======================

print("\n1Ô∏è‚É£ DECISION TREE CLASSIFIER")
print("Predicting Performance Category based on features")

# Features for classification
X_class = df_encoded[['Make_encoded', 'Segment_encoded', 'Body_Type_encoded',
                     'Average_Monthly_Sales', 'Sales_Variance', 'Peak_Month_Sales']]
y_class = df_encoded['Performance_Category']

# Remove any NaN values
mask = ~(X_class.isnull().any(axis=1) | y_class.isnull())
X_class = X_class[mask]
y_class = y_class[mask]

# Split the data
X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(
    X_class, y_class, test_size=0.3, random_state=42, stratify=y_class)

# Create and train the classifier
clf = DecisionTreeClassifier(random_state=42, max_depth=5, min_samples_split=5)
clf.fit(X_train_c, y_train_c)

# Make predictions
y_pred_c = clf.predict(X_test_c)

# Evaluate the classifier
print(f"Classification Accuracy: {accuracy_score(y_test_c, y_pred_c):.4f}")
print("\nClassification Report:")
print(classification_report(y_test_c, y_pred_c))

# Feature importance
feature_names_c = ['Make', 'Segment', 'Body_Type', 'Avg_Monthly_Sales', 'Sales_Variance', 'Peak_Month_Sales']
importance_c = pd.DataFrame({
    'Feature': feature_names_c,
    'Importance': clf.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nüìä Feature Importance (Classification):")
print(importance_c)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(importance_c['Feature'], importance_c['Importance'], color='steelblue')
plt.title('Feature Importance - Classification Model', fontsize=14, fontweight='bold')
plt.xlabel('Importance')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# =======================
# DECISION TREE REGRESSOR
# =======================

print("\n2Ô∏è‚É£ DECISION TREE REGRESSOR")
print("Predicting Total Sales based on features")

# Features for regression (using monthly sales data)
monthly_features = ['January', 'February', 'March', 'April', 'May', 'June']
X_reg = df_encoded[['Make_encoded', 'Segment_encoded', 'Body_Type_encoded'] + monthly_features]
y_reg = df_encoded['Total']

# Remove any NaN values
mask = ~(X_reg.isnull().any(axis=1) | y_reg.isnull())
X_reg = X_reg[mask]
y_reg = y_reg[mask]

# Split the data
X_train_r, X_test_r, y_train_r, y_test_r = train_test_split(
    X_reg, y_reg, test_size=0.3, random_state=42)

# Create and train the regressor
reg = DecisionTreeRegressor(random_state=42, max_depth=6, min_samples_split=5)
reg.fit(X_train_r, y_train_r)

# Make predictions
y_pred_r = reg.predict(X_test_r)

# Evaluate the regressor
mse = mean_squared_error(y_test_r, y_pred_r)
rmse = np.sqrt(mse)
r2 = r2_score(y_test_r, y_pred_r)

print(f"Regression Metrics:")
print(f"RMSE: {rmse:.2f}")
print(f"R¬≤ Score: {r2:.4f}")

# Feature importance for regression
feature_names_r = ['Make', 'Segment', 'Body_Type'] + monthly_features
importance_r = pd.DataFrame({
    'Feature': feature_names_r,
    'Importance': reg.feature_importances_
}).sort_values('Importance', ascending=False)

print("\nüìä Feature Importance (Regression):")
print(importance_r)

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(importance_r['Feature'], importance_r['Importance'], color='darkgreen')
plt.title('Feature Importance - Regression Model', fontsize=14, fontweight='bold')
plt.xlabel('Importance')
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

# =======================
# DECISION TREE VISUALIZATION
# =======================

print("\n3Ô∏è‚É£ DECISION TREE VISUALIZATION")

# Visualize the classification tree (limited depth for readability)
plt.figure(figsize=(20, 10))
plot_tree(clf, feature_names=feature_names_c, class_names=clf.classes_,
          filled=True, rounded=True, fontsize=10, max_depth=3)
plt.title('Decision Tree Classifier (Max Depth = 3)', fontsize=16, fontweight='bold')
plt.tight_layout()
plt.show()

# Text representation of the tree
print("\nüìù Decision Tree Rules (First few levels):")
tree_rules = export_text(clf, feature_names=feature_names_c, max_depth=3)
print(tree_rules)

# =======================
# BUSINESS INSIGHTS
# =======================

print("\n=== BUSINESS INSIGHTS ===")

# Segment analysis
segment_analysis = df.groupby('Segment').agg({
    'Total': ['sum', 'mean', 'count'],
    'Average_Monthly_Sales': 'mean',
    'YoY %': 'mean'
}).round(2)

print("\nüìà Segment Performance Analysis:")
print(segment_analysis)

# Make analysis
make_analysis = df.groupby('Make').agg({
    'Total': ['sum', 'count'],
    'YoY %': 'mean'
}).round(2)

print("\nüè≠ Top 10 Manufacturers by Total Sales:")
print(make_analysis.sort_values(('Total', 'sum'), ascending=False).head(10))

# Body type analysis
body_analysis = df.groupby('Body Type').agg({
    'Total': ['sum', 'mean', 'count'],
    'YoY %': 'mean'
}).round(2)

print("\nüöó Body Type Performance:")
print(body_analysis.sort_values(('Total', 'sum'), ascending=False))

# Seasonal analysis
seasonal_data = df[monthly_cols].sum()
print("\nüìÖ Monthly Sales Pattern:")
for month, sales in seasonal_data.items():
    print(f"{month}: {sales:,}")

# Plot seasonal pattern
plt.figure(figsize=(12, 6))
plt.plot(seasonal_data.index, seasonal_data.values, marker='o', linewidth=2, markersize=8)
plt.title('Monthly Sales Pattern - 2024', fontsize=14, fontweight='bold')
plt.xlabel('Month')
plt.ylabel('Total Sales')
plt.xticks(rotation=45)
plt.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

print("\n=== ANALYSIS COMPLETE ===")
print("Key Findings:")
print("1. Decision tree models can effectively predict car sales performance")
print("2. Monthly sales patterns show seasonal variations")
print("3. Different segments and body types have distinct performance characteristics")
print("4. Feature importance reveals which factors most influence sales success")